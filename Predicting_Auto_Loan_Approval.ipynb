{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vncDsAP0Gaoa"
      },
      "source": [
        "# **Predicting Auto Loan Approval**    -\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beRrZCGUAJYm"
      },
      "source": [
        "##### **Project Type**    - Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6K7xa23Elo4"
      },
      "source": [
        "# **GitHub Link -**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1o69JH3Eqqn"
      },
      "source": [
        "[GitHub Link to the project](https://github.com/Rajivjha003/Auto_Loan_Approval_Prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQaldy8SH6Dl"
      },
      "source": [
        "# **Problem Statement**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpeJGUA3kjGy"
      },
      "source": [
        "**Develop a machine learning algorithm to predict whether a loan application will be approved or rejected based on the provided applicant information.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhfV-JJviCcP"
      },
      "source": [
        "## ***1. Know Your Data***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3lxredqlCYt"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "\n",
        "## Python Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Display all the columns in the dataframe\n",
        "pd.pandas.set_option(\"display.max_columns\", None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RnN4peoiCZX"
      },
      "source": [
        "### Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eD_8VQm3ukDg"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "outputs": [],
      "source": [
        "# Load Dataset\n",
        "\n",
        "df = pd.read_excel(r\"/content/drive/MyDrive/Loan_approval.xlsx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x71ZqKXriCWQ"
      },
      "source": [
        "### Dataset First View"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "outputs": [],
      "source": [
        "# Dataset First Look\n",
        "df.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hBIi_osiCS2"
      },
      "source": [
        "### Dataset Rows & Columns count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "outputs": [],
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlHwYmJAmNHm"
      },
      "source": [
        "### Dataset Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "outputs": [],
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35m5QtbWiB9F"
      },
      "source": [
        "#### Duplicate Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "outputs": [],
      "source": [
        "# Dataset Duplicate Value Count\n",
        "\n",
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoPl-ycgm1ru"
      },
      "source": [
        "#### Missing Values/Null Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "outputs": [],
      "source": [
        "# Missing Values/Null Values Count\n",
        "\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ad-cg2nvuaLp"
      },
      "outputs": [],
      "source": [
        "missing_percnt=df.isnull().sum()/len(df)*100\n",
        "missing_percnt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "outputs": [],
      "source": [
        "# Visualizing the missing values\n",
        "plt.figure(figsize=(15, 5))\n",
        "sns.barplot(x=missing_percnt.index, y=missing_percnt)\n",
        "plt.xticks(rotation=60)\n",
        "plt.xlabel(\"Variables\")\n",
        "plt.ylabel(\"Missing Percentage\")\n",
        "plt.title(\"Missing Values\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0kj-8xxnORC"
      },
      "source": [
        "### About dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfoNAAC-nUe_"
      },
      "source": [
        "- In our dataset, we have a total of 29,394 rows and 21 columns.\n",
        "\n",
        "- We have missing values in the \"Income\", \"No. of Tradelines\", \"Vehicle Year\", \"Vehicle Make\", \"Vehicle Age\", and \"Vehicle Miles\"    column.\n",
        "- The \"Income\" column has 557 missing values, \"No. of Tradelines\" has 709 missing value\n",
        "- Most of the columns contain numeric data tyts), representing numerical attributes such as income, loan amount, and credit scores.\n",
        "- Some columns, such as \"CreditType\" and \"Vehicle Make\", are categorical, containing object data ty\n",
        "- There are no duplicate rows in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      },
      "source": [
        "## ***2. Understanding Your Variables***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "outputs": [],
      "source": [
        "# Dataset Columns\n",
        "\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "outputs": [],
      "source": [
        "# Dataset Describe\n",
        "\n",
        "df.describe().T.round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBTbrJXOngz2"
      },
      "source": [
        "### Variables Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJV4KIxSnxay"
      },
      "source": [
        "1.\tLoan Number: Unique identifier for each loan application.\n",
        "2.\tCreditType: Type of credit (e.g., prime, subprime).\n",
        "3.\tJob Hours: Number of hours worked per week by the applicant.\n",
        "4.\tIncome: Monthly income of the applicant.\n",
        "5.\tLTV (Loan-to-Value): Ratio of the loan amount to the appraised value of the vehicle.\n",
        "6.\tTerm: Duration of the loan in months.\n",
        "7.\tPrice: Price of the vehicle being financed.\n",
        "8.\tDownpayment: Amount of downpayment made by the applicant.\n",
        "9.\tBookValue: Book value of the vehicle.\n",
        "10.\tAmount Financed: The amount of the loan being applied for.\n",
        "11.\tAPR (Annual Percentage Rate): Annualized interest rate on the loan.\n",
        "12.\tMonthly Payment: Monthly payment amount.\n",
        "13.\tMonthly Debt: Total monthly debt obligations of the applicant.\n",
        "14.\tNo. of Tradelines: Number of credit tradelines (credit accounts) reported for the applicant.\n",
        "15.\tFICO Score: FICO credit score of the applicant.\n",
        "16.\tClearFraud Score: Fraud risk score assigned to the applicant.\n",
        "17.\tVehicle Year: Year of the vehicle being financed.\n",
        "18.\tVehicle Make: Make of the vehicle.\n",
        "19.\tVehicle Age: Age of the vehicle.\n",
        "20.\tVehicle Miles: Mileage of the vehicle.\n",
        "21.\tAutoApproved (Target): Binary variable indicating whether the loan was approved (1) or rejected (0).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3PMJOP6ngxN"
      },
      "source": [
        "### Check Unique Values for each variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "outputs": [],
      "source": [
        "# Check Unique Values for each variable.\n",
        "\n",
        "df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrahG4_QuaLw"
      },
      "outputs": [],
      "source": [
        "df[\"CreditType\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hn7cLwZsuaLw"
      },
      "outputs": [],
      "source": [
        "df[\"AutoApproved\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dauF4eBmngu3"
      },
      "source": [
        "## 3. ***Data Wrangling***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKJF3rekwFvQ"
      },
      "source": [
        "### Data Wrangling Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "outputs": [],
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "\n",
        "num_col=df.select_dtypes(include=[\"int\", \"float\"])\n",
        "cat_col=df.select_dtypes(include=[\"object\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2WIs1tXuaL7"
      },
      "outputs": [],
      "source": [
        "df.drop(\"Vehicle Make\", axis=1, inplace= True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDTJZ8CeuaL8"
      },
      "source": [
        "### Summary Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ipa0tpL4uaL8"
      },
      "outputs": [],
      "source": [
        "stats = num_col.describe().T.round(2)\n",
        "stats['skew'] = num_col.skew().round(2)\n",
        "stats['kurtosis'] = num_col.kurtosis().round(2)\n",
        "\n",
        "stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF8Ens_Soomf"
      },
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wOQAZs5pc--"
      },
      "source": [
        "#### Chart - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "outputs": [],
      "source": [
        "# Chart - 1 visualization code\n",
        "sns.boxplot(x=\"AutoApproved\", y=\"Income\", showmeans=True, data=df)\n",
        "plt.xlabel(\"Loan Approved\")\n",
        "plt.ylabel(\"Income\")\n",
        "plt.title(\"Income Distribution by Loan Approval\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXrkDaPiuaMC"
      },
      "outputs": [],
      "source": [
        "df[\"Income\"].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEvgLQwzuaMD"
      },
      "outputs": [],
      "source": [
        "df.loc[df[\"Income\"] >= 250000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XESiWehPqBRc"
      },
      "source": [
        " Using boxplot to analyze the income distribution by loan approval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_j1G7yiqdRP"
      },
      "source": [
        "Income Distribution: The boxplot shows that the income distribution for approved loans is significantly higher than for rejected loans. The median income for approved loans is around 50,000, while for rejected loans, it's closer to $30,000. This suggests that income is a crucial factor in loan approval for ABC Auto Finance.\n",
        "\n",
        "Outliers: There appear to be outliers on both sides of the distribution, indicating that some high-income applicants were rejected and some low-income applicants were approved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cspy4FjqxJW"
      },
      "source": [
        "Improved Loan Approval Process: By understanding the relationship between income and loan approval, ABC Auto Finance can refine their credit risk assessment process. This can lead to approving more loans to qualified borrowers while reducing defaults.\n",
        "\n",
        "Targeted Marketing: The income distribution can help ABC Auto Finance target their marketing campaigns towards demographics with a higher likelihood of loan approval. This can improve the return on investment for their marketing efforts.\n",
        "\n",
        "Negative Impacts:\n",
        "\n",
        "Fairness and Bias: If the income distribution is skewed towards higher income groups due to biases in the loan approval process, it can limit access to loans for qualified low-income borrowers. This can have negative social and ethical implications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSlN3yHqYklG"
      },
      "source": [
        "#### Chart - 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4YgtaqtYklH",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Chart - 2 visualization code\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='LTV', y='AutoApproved', hue='AutoApproved', data=df, palette='Set1', alpha=0.7)\n",
        "\n",
        "# Adding a trendline or regression line\n",
        "sns.regplot(x='LTV', y='AutoApproved', data=df, scatter=False, color='black')\n",
        "\n",
        "plt.title('Scatterplot of Loan-to-Value (LTV) vs. AutoApproval')\n",
        "plt.xlabel('Loan-to-Value (LTV)')\n",
        "plt.ylabel('AutoApproval')\n",
        "plt.legend(title='AutoApproved', loc='upper right', labels=['Rejected', 'Approved'])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdq1hXG4uaMH",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "df.loc[(df[\"LTV\"] >= 500) & (df[\"AutoApproved\"] == 1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aaW0BYyYklI"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSx9atu2YklI"
      },
      "source": [
        "Negative Correlation: The plot confirms a negative correlation between LTV ratio and loan approval. Data points representing approved loans (green) are concentrated in the lower LTV ratio area (left side), while rejected loans (red) are scattered towards the higher LTV ratio area (right side). This indicates that borrowers with a higher LTV (larger loan amount relative to vehicle value) are less likely to get their loans approved\n",
        "\n",
        "Approval Threshold: The data suggests a possible LTV threshold around 400-500, where loan approvals become less frequent. This can be a starting point for ABC Auto Finance to define their LTV risk management strategies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcBbebzrYklV"
      },
      "source": [
        "hey can focus on approving loans with lower LTVs to mitigate defaults and improve loan portfolio health.\n",
        " By segmenting loan applications by LTV and approval status, ABC Auto Finance can target marketing campaigns more effectively. They can offer loan products with higher LTV limits to creditworthy borrowers who were previously rejected due to stricter thresholds"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "_BpIBETyuaML"
      },
      "source": [
        "Lost Business Opportunities: Overly strict LTV restrictions could prevent some creditworthy borrowers with moderate LTVs from obtaining loans. This might lead to lost business opportunities for ABC Auto Finance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM7whBJCYoAo"
      },
      "source": [
        "#### Chart - 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "outputs": [],
      "source": [
        "# Chart - 3 visualization code\n",
        "\n",
        "sns.boxplot(y=\"FICO\", x=\"AutoApproved\", data=df)\n",
        "plt.xlabel(\"FICO Score\")\n",
        "plt.ylabel(\"Loan Approved\")\n",
        "plt.title(\"FICO Score vs. Loan Approval\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dBItgRVYoAp"
      },
      "source": [
        "A box plot is an excellent choice for visualizing the relationship between two continuous variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jstXR6OYoAp"
      },
      "source": [
        "positive correlation between FICO score and loan approval.\n",
        "The scatter plot reveals a positive correlation between FICO score and loan approval. This means that there's a general tendency for applicants with higher FICO scores to have their loans approved. We can observe Applicants with higher FICO scores are generally more likely to get their loans approved in this data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      },
      "source": [
        "Improved Loan Approval Efficiency: By understanding the relationship between FICO score and approval rates, you can potentially streamline the loan approval process. For instance, applications with very high FICO scores (e.g., above 750) might qualify for faster approvals or require less manual review.\n",
        "Reduced Risk: Focusing on applicants with strong creditworthiness (high FICO scores) can help reduce the risk of defaults, leading to lower delinquency rates and improved portfolio health for your auto finance business.\n",
        "Are there negative impacts?\n",
        "\n",
        "While a FICO score is a valuable indicator, relying solely on it could lead to potential drawbacks:\n",
        "\n",
        "Fair Lending Concerns: Using FICO scores as the primary criterion might raise fair lending concerns if it disproportionately excludes applicants from certain demographics with lower average credit scores but who might be creditworthy nonetheless. Regulatory compliance and fair lending practices are crucial considerations.\n",
        "Missing Out on Good Borrowers: Some borrowers with lower FICO scores might still be good candidates for loans if they have other positive attributes, such as steady employment, stable income, or a history of on-time payments for other debts. A more holistic approach to evaluating loan applications can help capture these nuances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Of9eVA-YrdM"
      },
      "source": [
        "#### Chart - 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "outputs": [],
      "source": [
        "# Chart - 4 visualization code\n",
        "\n",
        "plt.figure(figsize=(15, 6))\n",
        "sns.scatterplot(x='Amount Financed', y='Price', data=df)\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.xlabel('Loan Amount (Log Scale)')\n",
        "plt.ylabel('Vehicle Price (Log Scale)')\n",
        "plt.title('Loan Amount vs. Vehicle Price (Logarithmic Scale)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      },
      "source": [
        "There's a clear positive correlation between loan amount and vehicle price. As vehicle prices increase (on a logarithmic scale), loan amounts also tend to increase. This makes sense - more expensive vehicles typically require larger loans\n",
        "\n",
        "The data points are not clustered around a straight line, but rather follow a curved pattern. This indicates a non-linear relationship. The increase in loan amount might not be directly proportional to the increase in vehicle price. For example, the jump in loan amount for a luxury car compared to a mid-range car might be smaller than the price difference between them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLNxxz7MYrdP"
      },
      "source": [
        "Loan Product Design: This scatter plot can inform the development of targeted loan products. By understanding the loan amount range needed for different vehicle price segments (e.g., budget-friendly cars vs. luxury vehicles), we can tailor loan offerings (like maximum loan amount) to specific customer segments. This can attract a wider range of customers and potentially increase loan applications.\n",
        "Credit Risk Assessment: Loan amount can be a factor influencing creditworthiness. Analyzing this plot alongside loan approval data can help assess if there's a relationship between the loan amount financed and the likelihood of loan approval. This knowledge can be valuable for developing credit risk assessment models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bamQiAODYuh1"
      },
      "source": [
        "#### Chart - 5"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "source": [
        "# Chart - 5 visualization code\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='Amount Financed', hue='Term', data=df)\n",
        "plt.xlabel('Loan Amount')\n",
        "plt.ylabel('Loan Term Count')\n",
        "plt.title('Loan Term Distribution by Loan Amount')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH-pJp9IphqM"
      },
      "source": [
        "#### Chart - 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "outputs": [],
      "source": [
        "# Chart - 6 visualization code\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "sns.kdeplot(x=df['ClearFraud Score'], y=df['AutoApproved'])\n",
        "plt.xlabel('ClearFraud Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of ClearFraud Score')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loh7H2nzphqN"
      },
      "source": [
        "KDE plots are well-suited for representing the distribution of continuous data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VECbqPI7phqN"
      },
      "source": [
        "ClearFraud score has a limited impact on loan approval because approvals happen across the entire score range above 250, and applicants with 0 scores are automatically rejected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIIx-8_IphqN"
      },
      "source": [
        "#### Chart - 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "outputs": [],
      "source": [
        "# Chart - 7 visualization code\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(x=\"CreditType\", y=\"AutoApproved\", data=df)\n",
        "plt.xlabel(\"Credit Type\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Count of Auto Approval by Credit Type\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZR9WyysphqO"
      },
      "source": [
        "#### Chart - 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "outputs": [],
      "source": [
        "# Chart - 8 visualization code\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.kdeplot(x=df['APR'], y=df['AutoApproved'])\n",
        "plt.xlabel('APR (%)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Annual Percentage Rate (APR)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJ55k-q6phqO"
      },
      "source": [
        "#### Chart - 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "outputs": [],
      "source": [
        "# Chart - 9 visualization code\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(\n",
        "    x=\"AutoApproved\",\n",
        "    y=\"No. of Tradelines\",\n",
        "    data=df,\n",
        ")\n",
        "plt.xlabel('Loan Approval')\n",
        "plt.ylabel('No. of Tradelines')\n",
        "plt.title('No. of Tradelines by Loan Approval')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVxDimi2phqP"
      },
      "source": [
        " scatter plots to see if there's a direct relationship between the number of tradelines and auto approval rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngGi97qjphqQ"
      },
      "source": [
        "The plot might visually show that the points for \"No. of Tradelines\" is higher for non-approved loans compared to approved loans. This suggests a correlation - there's a relationship between the two variables. However, it doesn't necessarily mean that having more accounts causes loan rejections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      },
      "source": [
        "#### Chart - 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "outputs": [],
      "source": [
        "# Chart - 10 visualization code\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "sns.scatterplot(x='Downpayment', y='LTV', data=df)\n",
        "plt.xlabel('Down Payment')\n",
        "plt.ylabel('Loan-to-Value (LTV) Ratio')\n",
        "plt.title('Down Payment vs. LTV Ratio')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qp13pnNzphqQ"
      },
      "source": [
        "the data points in the scatter plot exhibit a positive correlation. This means there's a general tendency for loan-to-value ratios to increase as down payments increase.\n",
        "a larger down payment reduces the lender's risk, so they might be more willing to approve a loan with a higher LTV\n",
        "The scatter plot likely suggests a non-linear relationship between down payment and LTV ratio. The data points are not clustered around a straight line, but rather follow a curved pattern. This indicates that the increase in LTV ratio might not be directly proportional to the increase in down payment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-EpHcCOp1ci"
      },
      "source": [
        "#### Chart - 11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "outputs": [],
      "source": [
        "# Chart - 11 visualization code\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x='Monthly Payment', y='Income', data=df)\n",
        "plt.xlabel('Monthly Loan Payment')\n",
        "plt.ylabel('Income')\n",
        "plt.title('Monthly Payment vs. Income')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      },
      "source": [
        "The scatter plot shows a weak positive correlation between monthly loan payment and income. There's a slight upward trend, indicating that borrowers with higher incomes tend to take out loans with higher monthly payments. However, the data points are quite spread out, suggesting a weak association.\n",
        "The plot reveals that borrowers with similar loan payments can have significantly different incomes.\n",
        "For some borrowers, especially those on the lower end of the income spectrum, the monthly payment might represent a significant portion of their income. This could be a risk factor, potentially leading to defaults if unexpected financial burdens arise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3dbpmDWp1ck"
      },
      "source": [
        "#### Chart - 12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "outputs": [],
      "source": [
        "# Chart - 12 visualization code\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(df['Monthly Dedt'], df['AutoApproved'], c=df['AutoApproved'], cmap='coolwarm')\n",
        "plt.xlabel('Monthly Debt')\n",
        "plt.ylabel('Loan Approval (0-Rejected, 1-Approved)')\n",
        "plt.title('Monthly Debt vs. Loan Approval')\n",
        "plt.colorbar(label='Loan Approval')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-lUsV2mp1ck"
      },
      "source": [
        "the color gradient (coolwarm) indicates a positive correlation between monthly debt and loan approval. This means there's a general tendency for applicants with higher monthly debt to be more likely to get their loans approved (represented by warmer colors). However, the data points are spread out, suggesting this relationship is not very strong."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ag9LCva-p1cl"
      },
      "source": [
        "#### Chart - 13"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "outputs": [],
      "source": [
        "# Chart - 13 visualization code\n",
        "feature1 = 'LTV'\n",
        "feature2 = 'Income'\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(df[feature1], df[feature2], c=df['AutoApproved'], cmap='coolwarm')\n",
        "plt.xlabel(feature1)\n",
        "plt.ylabel(feature2)\n",
        "plt.title('Interaction Plot: ' + feature1 + ' vs. ' + feature2)\n",
        "plt.colorbar(label='Loan Approval Probability')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      },
      "source": [
        "LTV vs. Income and Loan Approval\n",
        "\n",
        "Trend by Color: The color gradient (coolwarm) indicates a possible trend between LTV, income, and loan approval probability. Here's a general interpretation based on color:\n",
        "\n",
        "Red: Lower loan approval probability (applicants with this combination of LTV and income are less likely to get approved).\n",
        "Yellow: Intermediate loan approval probability.\n",
        "Blue: Higher loan approval probability (applicants with this combination of LTV and income are more likely to get approved).\n",
        "Spread of Data Points: The data points are scattered, meaning the relationship between LTV, income, and approval probability is not perfectly linear. There can be applicants with similar LTV and income who have varying loan approval outcomes (red, yellow, or blue)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC_X3p0fY2L0"
      },
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "outputs": [],
      "source": [
        "# Correlation Heatmap visualization code\n",
        "\n",
        "plt.figure(figsize=(15, 6))\n",
        "correlation = df.select_dtypes(include=[np.number]).corr()\n",
        "sns.heatmap(correlation, annot=True, cmap=\"twilight_shifted_r\")\n",
        "plt.title('Correlation Matrix of Numerical Features')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q29F0dvdveiT"
      },
      "source": [
        "#### Chart - 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "outputs": [],
      "source": [
        "# visualization code\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(df['Price'], df['BookValue'])\n",
        "plt.xlabel('Vehicle Price')\n",
        "plt.ylabel('Book Value')\n",
        "plt.title('Book Value vs. Vehicle Price')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPQ8RGwHveiV"
      },
      "source": [
        "The data points in the scatter plot exhibit a positive correlation. This means there's a general tendency for book value to increase as vehicle price increases. In simpler terms, more expensive cars tend to have a higher book value, which reflects their market worth.\n",
        "\n",
        "The data points are scattered around the positive trend line, indicating that the relationship between book value and vehicle price is not perfectly linear. Here are some possible reasons for this spread:\n",
        "\n",
        "Vehicle Make and Model: Even for similar prices, different car makes and models might have different book values due to factors like brand reputation, features, and demand.\n",
        "Vehicle Condition: The condition of a car (mileage, wear and tear) can significantly impact its book value, even if the price is the same. A car in good condition will likely have a higher book value than a car with similar features but poorer condition.\n",
        "Geographic Location: Geographic location can also influence book value. The same car model might have a different book value in different parts of the country."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-ATYxFrGrvw"
      },
      "source": [
        "## ***5. Hypothesis Testing***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yEUt7NnHlrM"
      },
      "source": [
        "### Hypothetical Statement - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI9ZP0laH0D-"
      },
      "source": [
        "Null Hypothesis (H0): There is no significant association between the number of job hours worked per week ('Job Hours') and loan approval rates ('AutoApproved').\n",
        "\n",
        "Alternative Hypothesis (Ha): Applicants with a higher number of job hours (potentially indicating full-time employment) are more likely to get their loans approved compared to applicants with fewer job hours (potentially part-time or unemployed)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I79__PHVH19G"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "outputs": [],
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "u_statistic, p_value = mannwhitneyu(df[df['AutoApproved'] == 0]['Job Hours'], df[df['AutoApproved'] == 1]['Job Hours'])\n",
        "\n",
        "\n",
        "print(\"mannwhitneyu statistic:\", u_statistic)\n",
        "print(\"p-value:\", p_value)\n",
        "\n",
        "# Interpretation\n",
        "if p_value < 0.05: \n",
        "    print(\"We can reject the null hypothesis. There is a significant association between job hours and loan approval rates.\")\n",
        "    print(\"Applicants with higher job hours are more likely to get their loans approved.\")\n",
        "else:\n",
        "    print(\"We fail to reject the null hypothesis. There is not enough evidence to conclude a significant difference in approval rates based on job hours.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2U0kk00ygSB"
      },
      "source": [
        "Mann-Whitney U Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO4K0gP5y3B4"
      },
      "source": [
        "This is a non-parametric test suitable for comparing the medians of two independent groups (approved vs. rejected loans in this case).\n",
        "We don't necessarily know if the distribution of the number of credit tradelines is normal (which is an assumption for a t-test).\n",
        "The Mann-Whitney U Test is a robust option that makes fewer assumptions about the data distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_0_7-oCpUZd"
      },
      "source": [
        "### Hypothetical Statement - 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwyV_J3ipUZe"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      },
      "source": [
        "Null Hypothesis (H0): There is no significant association between income level and loan approval rates.\n",
        "Alternative Hypothesis (Ha): Loan approval rates are positively correlated with income level"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yB-zSqbpUZe"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "outputs": [],
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "income_groups = pd.cut(df['Income'], bins=3, labels=['Low', 'Medium', 'High'])\n",
        "contingency_table = pd.crosstab(income_groups, df['AutoApproved'])\n",
        "\n",
        "# Perform Chi-Square test with Yates' Correction\n",
        "chi2_statistic, p_value, expected_table, obs_table = chi2_contingency(contingency_table, correction=True)\n",
        "\n",
        "print(\"Chi-Square Statistic:\", chi2_statistic)\n",
        "print(\"p-value:\", p_value)\n",
        "\n",
        "# Interpretation\n",
        "if p_value < 0.05:\n",
        "    print(\"We can reject the null hypothesis. There is a significant association between income level and loan approval rates.\")\n",
        "else:\n",
        "    print(\"We fail to reject the null hypothesis. There is not enough evidence to conclude a significant association between income level and loan approval rates.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLDrPz7HpUZf"
      },
      "source": [
        "Chi-Square Statistic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xOGYyiBpUZf"
      },
      "source": [
        " Chi-Square test with Yates' Correction is the most suitable option because it considers the categorical nature of the loan approval data and provides a robust p-value even for potential limitations in sample size or data sparsity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn_IUdTipZyH"
      },
      "source": [
        "### Hypothetical Statement - 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49K5P_iCpZyH"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gWI5rT9pZyH"
      },
      "source": [
        "Null Hypothesis (H0): There is no significant difference in loan approval rates between applicants with prime and subprime credit type\n",
        "Alternative Hypothesis (Ha): Applicants with prime credit (e.g., higher credit scores, lower debt-to-income ratio) are more likely to get their loans approved compared to applicants with subprime credit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nff-vKELpZyI"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "outputs": [],
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "contingency_table = pd.crosstab(df['CreditType'], df['AutoApproved'])\n",
        "chi2_statistic, p_value, expected_table, obs_table = chi2_contingency(contingency_table)\n",
        "\n",
        "print(\"Chi-Square Statistic:\", chi2_statistic)\n",
        "print(\"p-value:\", p_value)\n",
        "# Interpretation\n",
        "if p_value < 0.05:\n",
        "    print(\"We can reject the null hypothesis. There is a significant association between credit type and loan approval rates.\")\n",
        "else:\n",
        "    print(\"We fail to reject the null hypothesis. There is not enough evidence to conclude a significant difference in approval rates between prime and subprime borrowers.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytWJ8v15pZyI"
      },
      "source": [
        "Chi-Square Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M99G98V6pZyI"
      },
      "source": [
        "- 'CreditType' is a categorical variable (prime, subprime).\n",
        "- 'AutoApproved' is a binary variable (approved/rejected)\n",
        "- We want to assess the association between these two categorical variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLjJCtPM0KBk"
      },
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id1riN9m0vUs"
      },
      "source": [
        "### 2. Handling Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "outputs": [],
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "\n",
        "def calculate_outlier(df, column):\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    IQR = Q3 - Q1\n",
        "    lower = Q1 - 1.5 * IQR\n",
        "    upper = Q3 + 1.5 * IQR\n",
        "    outliers = df[(df[column] > upper) | (df[column] < lower)]\n",
        "    percent_outliers = round((outliers.shape[0] / df.shape[0]) * 100, 2)\n",
        "    return lower, upper, percent_outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_36E2qLYuaNi"
      },
      "outputs": [],
      "source": [
        "num_col.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQeV-41UuaNj"
      },
      "outputs": [],
      "source": [
        "lower_income, upper_income, percentage_income_outliers=calculate_outlier(df, \"Income\")\n",
        "print(\"lower band\",(lower_income))\n",
        "print(\"upper band\",(upper_income))\n",
        "print(\"outlier percent\",(percentage_income_outliers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_X3pna2MuaNj"
      },
      "outputs": [],
      "source": [
        "df[\"Income\"].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCRRywekuaNk"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(x=\"AutoApproved\", y=\"Income\", showmeans=True, data=df)\n",
        "plt.xlabel(\"Loan Approved\")\n",
        "plt.ylabel(\"Income\")\n",
        "plt.title(\"Income Distribution by Loan Approval\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXRU_vHGuaNk"
      },
      "outputs": [],
      "source": [
        "df.loc[df[\"Income\"]<= 0, \"Sales\" ]=0\n",
        "df.loc[df[\"Income\"]>= 250000, \"Sales\" ]=250000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQLORGJhuaNl"
      },
      "outputs": [],
      "source": [
        "# For LTV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPcz3FViuaNl"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(x=\"AutoApproved\", y=\"LTV\", showmeans=True, data=df)\n",
        "plt.xlabel(\"AutoApproved\")\n",
        "plt.ylabel(\"Income\")\n",
        "plt.title(\"LTV Distribution by Loan Approval\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDwzmyozuaNl"
      },
      "outputs": [],
      "source": [
        "lower_LTV, upper_LTV, percentage_LTV_outliers=calculate_outlier(df, \"LTV\")\n",
        "print(\"lower band\",(lower_LTV))\n",
        "print(\"upper band\",(upper_LTV))\n",
        "print(\"outlier percent\",(percentage_LTV_outliers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzHRaOQNuaNm"
      },
      "outputs": [],
      "source": [
        "df.loc[df[\"LTV\"]<= 0, \"LTV\" ]=0\n",
        "df.loc[df[\"LTV\"]>= 2000, \"LTV\" ]=2000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jTPgl6GuaNm"
      },
      "outputs": [],
      "source": [
        "df[df[\"LTV\"]> 2000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nxs5yf31uaNn"
      },
      "outputs": [],
      "source": [
        "# For Term"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjIB1BhEuaNn"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(x=\"AutoApproved\", y=\"Term\", showmeans=True, data=df)\n",
        "plt.xlabel(\"Term\")\n",
        "plt.ylabel(\"Income\")\n",
        "plt.title(\"Term Distribution by Loan Approval\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhLoliusuaNo"
      },
      "outputs": [],
      "source": [
        "lower_Term, upper_Term, percentage_Term_outliers=calculate_outlier(df, \"Term\")\n",
        "print(\"lower band\",(lower_Term))\n",
        "print(\"upper band\",(upper_Term))\n",
        "print(\"outlier percent\",(percentage_Term_outliers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruoq-ViYuaNo"
      },
      "outputs": [],
      "source": [
        "df.loc[df[\"Term\"]>= 80, \"LTV\" ]=80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WT-it_cvuaNp"
      },
      "outputs": [],
      "source": [
        "# For Price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvXO5yeJuaNq"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 4))\n",
        "sns.scatterplot(x='AutoApproved', y='Price', data=df)\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.xlabel('Loan Amount (Log Scale)')\n",
        "plt.ylabel('Vehicle Price (Log Scale)')\n",
        "plt.title('Loan Amount vs. Vehicle Price (Logarithmic Scale)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gK1kuVSNuaNq"
      },
      "outputs": [],
      "source": [
        "lower_Price, upper_Price, percentage_Price_outliers=calculate_outlier(df, \"Price\")\n",
        "print(\"lower band\",(lower_Price))\n",
        "print(\"upper band\",(upper_Price))\n",
        "print(\"outlier percent\",(percentage_Price_outliers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTdB4RLQuaNr"
      },
      "outputs": [],
      "source": [
        "# For Downpayment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoivWzwluaNr"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(x=\"AutoApproved\", y=\"Downpayment\", showmeans=True, data=df)\n",
        "plt.xlabel(\"AutoApproved\")\n",
        "plt.ylabel(\"Downpayment\")\n",
        "plt.title(\"Downpayment Distribution by Loan Approval\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoJ96MCguaNs"
      },
      "outputs": [],
      "source": [
        "lower_Downpayment, upper_Downpayment, percentage_Downpayment_outliers=calculate_outlier(df, \"Downpayment\")\n",
        "print(\"lower band\",(lower_Downpayment))\n",
        "print(\"upper band\",(upper_Downpayment))\n",
        "print(\"outlier percent\",(percentage_Downpayment_outliers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DrDMKSWuaNs"
      },
      "outputs": [],
      "source": [
        "df.loc[df[\"Downpayment\"] < 0, \"Downpayment\" ]=0\n",
        "df.loc[df[\"Downpayment\"]>= 200000, \"Downpayment\" ]=200000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waR7OTGouaNt"
      },
      "outputs": [],
      "source": [
        "# For BookValue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnsmqfFauaNt"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(x=\"AutoApproved\", y=\"BookValue\", showmeans=True, data=df)\n",
        "plt.xlabel(\"AutoApproved\")\n",
        "plt.ylabel(\"BookValue\")\n",
        "plt.title(\"BookValue Distribution by Loan Approval\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOMmYZSduaNt"
      },
      "outputs": [],
      "source": [
        "lower_BookValue, upper_BookValue, percentage_BookValue_outliers=calculate_outlier(df, \"BookValue\")\n",
        "print(\"lower band\",(lower_BookValue))\n",
        "print(\"upper band\",(upper_BookValue))\n",
        "print(\"outlier percent\",(percentage_BookValue_outliers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uv4WpgGfuaNu"
      },
      "outputs": [],
      "source": [
        "df.loc[df[\"BookValue\"] < 0, \"BookValue\" ]=0\n",
        "df.loc[df[\"BookValue\"]>= 300000, \"BookValue\" ]=300000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwJRnpncuaNu"
      },
      "outputs": [],
      "source": [
        "# For Amount Financed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Z3bdAG8uaNv"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 4))\n",
        "sns.scatterplot(x='AutoApproved', y='Amount Financed', data=df)\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.xlabel('AutoApproved (Log Scale)')\n",
        "plt.ylabel('Amount Financed (Log Scale)')\n",
        "plt.title('AutoApproved vs. VAmount Financed (Logarithmic Scale)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juerWUbAuaNv"
      },
      "outputs": [],
      "source": [
        "df.loc[df[\"Amount Financed\"] < 0, \"Amount Financed\" ]=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRIa456PuaNw"
      },
      "outputs": [],
      "source": [
        "# For APR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1Op9xW3uaNw"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(x=\"AutoApproved\", y=\"APR\", showmeans=True, data=df)\n",
        "plt.xlabel(\"AutoApproved\")\n",
        "plt.ylabel(\"APR\")\n",
        "plt.title(\"APR Distribution by Loan Approval\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWhFqNQcuaNw"
      },
      "outputs": [],
      "source": [
        "lower_APR, upper_APR, percentage_APR_outliers=calculate_outlier(df, \"APR\")\n",
        "print(\"lower band\",(lower_APR))\n",
        "print(\"upper band\",(upper_APR))\n",
        "print(\"outlier percent\",(percentage_APR_outliers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsyU0otAuaNx"
      },
      "outputs": [],
      "source": [
        "df.loc[df[\"APR\"]>= 34, \"APR\" ]=34"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wag4vGS8uaNx"
      },
      "outputs": [],
      "source": [
        "# For Monthly Payment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irLBkxR8uaNy"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(x=\"AutoApproved\", y=\"Monthly Payment\", showmeans=True, data=df)\n",
        "plt.xlabel(\"AutoApproved\")\n",
        "plt.ylabel(\"Monthly Payment\")\n",
        "plt.title(\"Monthly Payment Distribution by Loan Approval\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySg0IE6quaNy"
      },
      "outputs": [],
      "source": [
        "lower_Monthly_Payment, upper_Monthly_Payment, percentage_Monthly_Payment_outliers=calculate_outlier(df, \"Monthly Payment\")\n",
        "print(\"lower band\",(lower_Monthly_Payment))\n",
        "print(\"upper band\",(upper_Monthly_Payment))\n",
        "print(\"outlier percent\",(percentage_Monthly_Payment_outliers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55YGBjlIuaNz"
      },
      "outputs": [],
      "source": [
        "# For Monthly_Debt\n",
        "\n",
        "sns.boxplot(x=\"AutoApproved\", y=\"Monthly Dedt\", showmeans=True, data=df)\n",
        "plt.xlabel(\"AutoApproved\")\n",
        "plt.ylabel(\"Monthly Debt\")\n",
        "plt.title(\"Monthly Debt Distribution by Loan Approval\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cWoITH7uaNz"
      },
      "outputs": [],
      "source": [
        "lower_Monthly_Debt, upper_Monthly_Debt, percentage_Monthly_Debt_outliers=calculate_outlier(df, \"Monthly Dedt\")\n",
        "print(\"lower band\",(lower_Monthly_Debt))\n",
        "print(\"upper band\",(upper_Monthly_Debt))\n",
        "print(\"outlier percent\",(percentage_Monthly_Debt_outliers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyH1_WwxuaNz"
      },
      "outputs": [],
      "source": [
        "df.loc[df[\"Monthly Dedt\"]>= 120000, \"Monthly Dedt\" ]=120000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xM10vbfRuaN0"
      },
      "outputs": [],
      "source": [
        "columns_to_check = [\"Income\", \"LTV\", \"Term\", \"Price\", \"Downpayment\", \"BookValue\", \"Amount Financed\",\n",
        "                    \"APR\", \"Monthly Payment\", \"Monthly Dedt\", \"No. of Tradelines\", \"FICO\",\n",
        "                    \"ClearFraud Score\", \"Vehicle Year\", \"Vehicle Age\", \"Vehicle Miles\"]\n",
        "\n",
        "for column in columns_to_check:\n",
        "    lower, upper, percent_outliers = calculate_outlier(df, column)\n",
        "    print(f\"For {column}:\")\n",
        "    print(\"Lower band:\", lower)\n",
        "    print(\"Upper band:\", upper)\n",
        "    print(\"Outlier percent:\", percent_outliers)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaApWKzWuaN1"
      },
      "outputs": [],
      "source": [
        "### 2. Handling Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tAjpASCuaN1"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpZ9uZMQuaN2"
      },
      "outputs": [],
      "source": [
        "df[df[[\"Vehicle Year\", \"Vehicle Age\", \"Vehicle Miles\"]].isnull().any(axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiZ6thLquaN2"
      },
      "outputs": [],
      "source": [
        "df[\"Income\"]=df[\"Income\"].transform(lambda x:x.fillna(x.mean()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aB-daHvzuaN3"
      },
      "outputs": [],
      "source": [
        "df[\"No. of Tradelines\"]=df[\"No. of Tradelines\"].transform(lambda x:x.fillna(x.mean()))\n",
        "df[\"Vehicle Year\"] = df[\"Vehicle Year\"].fillna(df[\"Vehicle Year\"].mode()[0])\n",
        "df[\"Vehicle Age\"] = df[\"Vehicle Age\"].fillna(df[\"Vehicle Age\"].mode()[0])\n",
        "df[\"Vehicle Miles\"] = df[\"Vehicle Miles\"].fillna(df[\"Vehicle Miles\"].mode()[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ikqr44PuaN3"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rq1J82WauaN4"
      },
      "outputs": [],
      "source": [
        "df.drop(columns=['Sales', 'ApplNbr'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89xtkJwZ18nB"
      },
      "source": [
        "### 3. Categorical Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21JmIYMG2hEo",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Encode your categorical columns\n",
        "df[\"CreditType\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9OKgHnZuaN6"
      },
      "outputs": [],
      "source": [
        "df[\"CreditType\"] = df[\"CreditType\"].map({\"Individual\":0, \"Joint\":1})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      },
      "source": [
        "### 4. Feature Manipulation & Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C74aWNz2AliB"
      },
      "source": [
        "#### 1. Feature Manipulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "outputs": [],
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "correlation_matrix = num_col.corr()\n",
        "\n",
        "# Print correlation matrix\n",
        "print(\"Correlation Matrix:\")\n",
        "print(correlation_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DejudWSA-a0"
      },
      "source": [
        "#### 2. Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "source": [
        "##### Selecting features wisely to avoid overfitting\n",
        " Debt-to-Income Ratio (DTI):\n",
        "\n",
        "Calculation: Divide the total monthly debt (Monthly Debt) by the monthly income (Income).\n",
        "Interpretation: This ratio indicates the percentage of income used to cover existing debts. A higher DTI could suggest a higher risk of delinquency on a new loan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZ2CNXmCuaN9"
      },
      "outputs": [],
      "source": [
        "df['DTI'] = df['Monthly Dedt'] / df['Income']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYsaBDxduaN-"
      },
      "source": [
        " Loan-to-Value Ratio with Downpayment (LTV_DP):\n",
        "\n",
        "Calculation: Subtract the downpayment (Downpayment) from the loan amount (Amount Financed) and divide by the vehicle price (Price).\n",
        "Interpretation: This modified LTV considers the downpayment, potentially providing a more nuanced picture of the loan-to-vehicle value ratio. A lower LTV_DP might indicate a lower risk of default."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__BuNyEFuaN-"
      },
      "outputs": [],
      "source": [
        "df['LTV_DP'] = (df['Amount Financed'] - df['Downpayment']) / df['Price']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BsbHOlDquaN_"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mx8dwxe6uaN_"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5IsekV3uaOA"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(18, 8))\n",
        "sns.heatmap(df.corr(), annot=True, cmap=\"Dark2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78WughXeuaOA"
      },
      "outputs": [],
      "source": [
        "correlation_matrix = df.corr()\n",
        "\n",
        "correlation_matrix.head(39)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pcu8FxmhuaOB"
      },
      "outputs": [],
      "source": [
        "# Check for infinity values\n",
        "inf_mask = df.isin([np.inf, -np.inf])\n",
        "\n",
        "# Get rows with infinity values\n",
        "rows_with_inf = df[inf_mask.any(axis=1)]\n",
        "\n",
        "print(\"Rows with infinity values:\")\n",
        "rows_with_inf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yazXf3gCuaOB"
      },
      "outputs": [],
      "source": [
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a1f2CWEuaOC"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "merhIWKLuaOC"
      },
      "outputs": [],
      "source": [
        "df[\"DTI\"]=df[\"DTI\"].transform(lambda x:x.fillna(x.mean()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNVZ9zx19K6k"
      },
      "source": [
        "### 5. Data Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_00ziMKzuaOF"
      },
      "outputs": [],
      "source": [
        "df.loc[df[\"LTV_DP\"] < 0, \"LTV_DP\" ]=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lbWgIxOuaOF"
      },
      "outputs": [],
      "source": [
        "x=df.drop(\"AutoApproved\",axis=1)\n",
        "y=df[\"AutoApproved\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iY8Q3mrVuaOG"
      },
      "outputs": [],
      "source": [
        "stats = x.describe().T.round(2)\n",
        "stats['skew'] = x.skew().round(2)\n",
        "stats['kurtosis'] = x.kurtosis().round(2)\n",
        "\n",
        "stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UUpS68QDMuG"
      },
      "source": [
        "### 7. Handling Imbalanced Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tt_xA76nuaOI"
      },
      "outputs": [],
      "source": [
        "df[\"AutoApproved\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVwrSK-MuaOI"
      },
      "outputs": [],
      "source": [
        "df.groupby(\"AutoApproved\").size().plot(kind=\"pie\", autopct=\"% .2f\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1K_WSTfuaOJ"
      },
      "outputs": [],
      "source": [
        "x=df.drop(\"AutoApproved\",axis=1)\n",
        "y=df[\"AutoApproved\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsoTgMLxuaOJ"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "smote = BorderlineSMOTE(sampling_strategy='auto', k_neighbors=5)\n",
        "\n",
        "x, y = smote.fit_resample(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhH2vgX9EjGr"
      },
      "source": [
        "### 8. Data Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwOa3uokuaOK"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train,x_test, y_train,y_test=train_test_split(x,y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZvN5P_EuaOM"
      },
      "outputs": [],
      "source": [
        "### 7. Data Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-DXsj9fuaOM"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "rob_scaler = RobustScaler()\n",
        "x_train = rob_scaler.fit_transform(x_train)\n",
        "x_test = rob_scaler.transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8BXqD9kuaON"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(rob_scaler, \"scaling_chd.pkl\")\n",
        "scaling_loan = joblib.load('scaling_chd.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfCC591jGiD4"
      },
      "source": [
        "## ***7. ML Model Implementation***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      },
      "source": [
        "### ML Model - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "outputs": [],
      "source": [
        "# ML Model - 1 Implementation\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, RocCurveDisplay\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# Logistic Regression\n",
        "logistic_regression=LogisticRegression(max_iter=1000)\n",
        "# Fit the Algorithm\n",
        "logistic_regression.fit(x_train, y_train)\n",
        "# Predict on the model\n",
        "logistic_pred_y=logistic_regression.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArJBuiUVfxKd"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print(confusion_matrix(y_test,logistic_pred_y))\n",
        "print(accuracy_score(y_test, logistic_pred_y))\n",
        "print(classification_report(y_test,logistic_pred_y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4jTJ4TNuaOT"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, logistic_pred_y)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plotting the ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qY1EAkEfxKe"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "outputs": [],
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "param_grid={'C': [0.1, 1, 10], \"penalty\": [\"l2\"]}\n",
        "cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
        "logistic_regression=LogisticRegression(max_iter=1000)\n",
        "Logclf=GridSearchCV(logistic_regression, param_grid, cv=cv, n_jobs=-1, scoring=\"f1\")\n",
        "# Fit the Algorithm\n",
        "Logclf.fit(x_train, y_train)\n",
        "# Predict on the model\n",
        "best_params = Logclf.best_params_\n",
        "best_model = Logclf.best_estimator_\n",
        "y_pred=best_model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNJtnJ0kuaOU"
      },
      "outputs": [],
      "source": [
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      },
      "source": [
        "### ML Model - 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiZ8BjiUuaOW"
      },
      "outputs": [],
      "source": [
        "# ML Model - 2 Implementation\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "random_forest= RandomForestClassifier()\n",
        "# Fit the Algorithm\n",
        "random_forest.fit(x_train,y_train)\n",
        "# Predict on the model\n",
        "randomforest_y_pred=random_forest.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWYfwnehpsJ1"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Evaluation Metric Score chart\n",
        "print(confusion_matrix(y_test,randomforest_y_pred))\n",
        "print(accuracy_score(y_test, randomforest_y_pred))\n",
        "print(classification_report(y_test,randomforest_y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DM-zju6J48ma"
      },
      "outputs": [],
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_test, randomforest_y_pred)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plotting the ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "outputs": [],
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [None, 5, 10],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "# Perform grid search with cross-validation\n",
        "cv = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
        "rf_clf = GridSearchCV(random_forest, param_grid, cv=cv, n_jobs=-1, scoring='f1')\n",
        "\n",
        "# Fit the Algorithm\n",
        "rf_clf.fit(x_train, y_train)\n",
        "\n",
        "# Predict on the model\n",
        "best_params = rf_clf.best_params_\n",
        "best_model = rf_clf.best_estimator_\n",
        "rf_y_pred=best_model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBN3msaPuaOZ"
      },
      "outputs": [],
      "source": [
        "print(confusion_matrix(y_test,rf_y_pred))\n",
        "print(accuracy_score(y_test, rf_y_pred))\n",
        "print(classification_report(y_test,rf_y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fze-IPXLpx6K"
      },
      "source": [
        "### ML Model - 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjcY9UUzuaOe"
      },
      "outputs": [],
      "source": [
        "pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxTXxh8_uaOf"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "xgb_classifier = xgb.XGBClassifier()\n",
        "\n",
        "# Fit the model\n",
        "xgb_classifier.fit(x_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = xgb_classifier.predict(x_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2Swtk7K3Kpy"
      },
      "outputs": [],
      "source": [
        "### ML Model - 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9n4tmMAuaOe"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gradient_boosting = GradientBoostingClassifier()\n",
        "\n",
        "# Fit the model\n",
        "gradient_boosting.fit(x_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = gradient_boosting.predict(x_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKzkwFcU3JD9"
      },
      "outputs": [],
      "source": [
        "### ML Model - 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ANJ13hguaOg"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=5)  # Specify the number of neighbors to consider\n",
        "knn.fit(x_train, y_train)\n",
        "y_pred = knn.predict(x_test)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "outputs": [],
      "source": [
        "# ML Model - 6 Implementation\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "naive_bayes = GaussianNB()\n",
        "\n",
        "# Fit the Algorithm\n",
        "naive_bayes.fit(x_train, y_train)\n",
        "\n",
        "# Predict on the model\n",
        "nb_y_pred = naive_bayes.predict(x_test)\n",
        "print(confusion_matrix(y_test, nb_y_pred))\n",
        "print(accuracy_score(y_test, nb_y_pred))\n",
        "print(classification_report(y_test, nb_y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_CCil-SKHpo"
      },
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVFULclm5_B6"
      },
      "source": [
        "\n",
        "\n",
        "1.   Accuracy: This measures the overall percentage of correct predictions. However, in our case with an imbalanced dataset, accuracy alone might not be sufficient.\n",
        "\n",
        "2.   Precision and Recall: These metrics provide a more detailed picture of class-specific performance. Precision tells us how often a positive prediction is truly correct, while recall indicates how well we identify all actual positive cases.\n",
        "\n",
        "\n",
        "3.   F1-score: This combines precision and recall into a single metric, offering a balanced view of model performance.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBFFvTBNJzUa"
      },
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      },
      "source": [
        "Random Forest as the most suitable model because:\n",
        "\n",
        "* High Accuracy: Random Forest achieved the highest overall accuracy (77.27%),\n",
        "indicating strong predictive power.\n",
        "\n",
        "* Balanced Class Performance: It demonstrates a good balance between precision and recall for both classes, ensuring reliable predictions for both majority and minority classes.\n",
        "\n",
        "* Outlier Resilience: Compared to models like Logistic Regression, Random Forest is less susceptible to outliers in the data, leading to more robust predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEMTlxLz7V8T"
      },
      "outputs": [],
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# Calculate permutation importances\n",
        "perm_importance = permutation_importance(random_forest, x_test, y_test, n_repeats=10, random_state=42)\n",
        "\n",
        "# Get the feature importance scores\n",
        "feature_importance = perm_importance.importances_mean\n",
        "\n",
        "# Sort the features based on importance scores\n",
        "sorted_indices = np.argsort(feature_importance)[::-1]\n",
        "sorted_features = x.columns[sorted_indices]\n",
        "\n",
        "# Create the bar chart using seaborn\n",
        "sns.barplot(x=feature_importance[sorted_indices], y=sorted_features)\n",
        "\n",
        "# Set the labels and title\n",
        "plt.xlabel('Importance Score')\n",
        "plt.ylabel('Features')\n",
        "plt.title('Feature Importances')\n",
        "\n",
        "# Show the bar chart\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyNgTHvd2WFk"
      },
      "source": [
        "## ***8.*** ***Future Work***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH5McJBi2d8v"
      },
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "outputs": [],
      "source": [
        "# Save the File\n",
        "\n",
        "import joblib\n",
        "\n",
        "joblib.dump(random_forest, \"random_forest_loan.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      },
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "outputs": [],
      "source": [
        "# Load the File and predict unseen data.\n",
        "random_forest_loan = joblib.load('random_forest_loan.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4wYRNINR0wr"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test data\n",
        "predictions = random_forest_loan.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnMnpZqf8EUf"
      },
      "outputs": [],
      "source": [
        "predictions=pd.DataFrame(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hy7SuPa8Erg"
      },
      "outputs": [],
      "source": [
        "# Naming Column\n",
        "predictions = predictions.rename(columns={0: \"AutoApproved\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wi53kzoy8Tgv"
      },
      "outputs": [],
      "source": [
        "predictions.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCX9965dhzqZ"
      },
      "source": [
        "# **Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      },
      "source": [
        "Our evaluation identified Random Forest as the best model for Loan Approval due to its high accuracy, balanced performance on both classes in the imbalanced dataset, and resilience to outliers. Further analysis using permutation_importance can provide deeper understanding of the model's decision-making and potentially improve its performance."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
